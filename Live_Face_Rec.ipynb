{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"C:\\\\Users\\\\91957\\\\Desktop\\\\i\"\n",
    "image_dir = os.path.join(BASE_DIR,\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_faces():\n",
    "    encoded = {}\n",
    "\n",
    "    for dirpath, dnames, fnames in os.walk(image_dir): #OS.Walk() OS.walk() generate the file names in a directory tree by walking the tree either top-down or bottom-up. For each directory in the tree rooted at directory top (including top itself), it yields a 3-tuple (dirpath, dirnames, filenames).\n",
    "        for f in fnames:\n",
    "            if f.endswith(\".jpg\") or f.endswith(\".png\") or f.endswith(\".jpeg\") or f.endswith(\".PNG\") or f.endswith(\".JPG\") or f.endswith(\".JPEG\") :\n",
    "                face = face_recognition.load_image_file(\"n/\" + f)\n",
    "                face = imread(\"n/\" + f)\n",
    "                encoding = face_recognition.face_encodings(face)[0]\n",
    "                encoded[f.split(\".\")[0]] = encoding\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_face():\n",
    "    \n",
    "    faces = get_encoded_faces()\n",
    "    \n",
    "    known_face_encodings = list(faces.values())\n",
    "\n",
    "    known_face_names = list(faces.keys())\n",
    "\n",
    "    # Initialize some variable\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    process_this_frame = True\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        small_frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25) #to reduce the size\n",
    "        #If you wish to use CV2, you need to use the resizefunction. For example, this will resize both axes by half: small = cv2.resize(image, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "        rgb_small_frame = small_frame[:,:,::-1]  #since the input image is in the form of bgr so we reverse the array so -1 to rgb \n",
    "        \n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        for encodeFace,faceLoc in zip(face_encodings, face_locations):      #using zip to reduce the time complexity\n",
    "            matches = face_recognition.compare_faces(known_face_encodings,encodeFace,0.5) #threshold 0.5 is for 50% of the image matching\n",
    "            faceDis = face_recognition.face_distance(known_face_encodings, encodeFace) \n",
    "            matchIndex = np.argmin(faceDis) #Return indices of the minimum values along the given axis.\n",
    "            #The numpy.argmin() method returns indices of the min element of the array in a particular axis. \n",
    "            name =\"Unknown\" \n",
    "            \n",
    "            if matches[matchIndex]:\n",
    "                name = known_face_names[matchIndex]\n",
    "                y1,x2,y2,x1 = faceLoc\n",
    "                y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4   #since fx & fy =0.25 so, y1,x1*4  like that\n",
    "                cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "                cv2.rectangle(frame,(x1,y2-35), (x2,y2), (0,255,0), cv2.FILLED) #two frames for two one for bigger box another where name is dispayed that box with thickness 2 \n",
    "                cv2.putText(frame, name, (x1-6,y2-6),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),2)\n",
    "            if not matches[matchIndex]:\n",
    "                y1,x2,y2,x1 = faceLoc\n",
    "                y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "                cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0),2)\n",
    "                cv2.rectangle(frame,(x1,y2-35), (x2,y2), (0,255,0), cv2.FILLED)\n",
    "                cv2.putText(frame, name, (x1-6,y2-6),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),2)\n",
    "\n",
    "\n",
    "        # Display Result\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classify_face())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dnames, fnames in os.walk(image_dir):\n",
    "        print(fnames)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
